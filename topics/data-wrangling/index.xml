<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Wrangling on Rsquared Academy Blog</title>
    <link>/topics/data-wrangling/</link>
    <description>Recent content in Data Wrangling on Rsquared Academy Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2014-2017. All rights reserved.</copyright>
    <lastBuildDate>Sat, 16 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/topics/data-wrangling/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Import Data into R - Part 2</title>
      <link>/post/import-data-into-r-part-2/</link>
      <pubDate>Sat, 16 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/import-data-into-r-part-2/</guid>
      <description>IntroductionThis is the fourth post in the series Introduction to tidyverse. In the previous post, we learnt how to read data from delimited files and other statistical softwares. In this post we will learn to:
list sheets in an excel fileread data from excel sheetread specific cells from an excel sheetread a single rowread a single columnread several rowsread several columns</description>
    </item>
    
    <item>
      <title>Data Wrangling with dbplyr</title>
      <link>/post/data-wrangling-with-dbplyr/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/data-wrangling-with-dbplyr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Complete Guide to Importing Data into R - Part 2</title>
      <link>/post/a-complete-guide-to-importing-data-into-r-part-2/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/a-complete-guide-to-importing-data-into-r-part-2/</guid>
      <description>IntroductionThis is the fourth post in the series Data Wrangling with R. In the previous post, we learnt to import data from flat files, excel spreadsheets and statistical softwares. In this post, we will learn to import data from:
JSONXMLgooglesheetsJSONA lot of API data is available in the JSON format. You can use the jsonlite package to import JSON data into R.</description>
    </item>
    
    <item>
      <title>Exporting Data from R</title>
      <link>/post/exporting-data-from-r/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/exporting-data-from-r/</guid>
      <description> 
IntroductionThis is the fifth post in the series Data Wrangling with R. In the previous post, we learnt to import data from JSON, XML and googlesheets. In this post, we will learn to export data/code from R.
Files# readr::read_file()Lines# readr::read_lines()SummaryUp Next..</description>
    </item>
    
    <item>
      <title>Why you should purrr - Part 2</title>
      <link>/post/why-you-should-purrr-part-2/</link>
      <pubDate>Fri, 23 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/why-you-should-purrr-part-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Why you should purrr?</title>
      <link>/post/why-you-should-purrr-part-1/</link>
      <pubDate>Fri, 23 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/why-you-should-purrr-part-1/</guid>
      <description>This is the 10th post in the series Data Wrangling with R. In the previous post, we learnt helper functions in dplyr package. In this post, we will learn about purrr, an R package that enhances Râ€™s functional programming toolkit. Let us begin by installing and loading purrr and a set of other pacakges we will be using.
As we did in the earlier posts in this series, we will use a case study to explore the various features of the stringr package.</description>
    </item>
    
    <item>
      <title>Data Manipulation in R with dplyr - Part 3</title>
      <link>/post/data-manipulation-in-r-with-dplyr-part-3/</link>
      <pubDate>Sun, 28 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/data-manipulation-in-r-with-dplyr-part-3/</guid>
      <description>IntroductionThis is the ninth post in the series Data Wrangling with R. In the previous post, we learnt how to combine tables using the *_join() family of functions in dplyr.
In this post, we will explore a set of helper functions in order to:
extract unique rowsrename columnssample dataextract columnsslice rowsarrange rowscompare tablesextract/mutate data using predicate functionscount observations for different levels of a variableCase StudyLet us look at a case study (e-commerce data) and see how we can use dplyr helper functions to answer questions we have about and to modify/transform the underlying data set.</description>
    </item>
    
    <item>
      <title>Data Manipulation in R with dplyr - Part 2</title>
      <link>/post/data-manipulation-in-r-with-dplyr-part-2/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/data-manipulation-in-r-with-dplyr-part-2/</guid>
      <description>IntroductionThis is the eighth post in the series Data Wrangling with R. In a previous post, we learnt about dplyr verbs and used them to compute average order value for an e-commerce website data. In this post, we will learn to combine tables using different join functions provided in dplyr. Let us assume we have 2 tables y and y. Below are the different types of join functions provided in dplyr.</description>
    </item>
    
    <item>
      <title>Introduction to tibbles</title>
      <link>/post/introduction-to-tibbles/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/introduction-to-tibbles/</guid>
      <description>IntroductionThis is the second post in the series Data Wrangling with R. In the previous post, we introduced tidyverse. In this post, we will learn about tibbles, a modern version of data frames that retain the good aspects (of data frames) while getting rid of the frustrating and annoying parts. tibbles are part of the tidyverse. In this post, we will learn how tibbles makes certain parts of the data analysis workflow easier by being different from data frames.</description>
    </item>
    
    <item>
      <title>Getting started with tidyverse</title>
      <link>/post/getting-started-with-tidyverse/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/getting-started-with-tidyverse/</guid>
      <description>This is the first post in the series Data Wrangling with R. In this series, we will look at the challenges faced when working with data of different types coming from different sources and explore tools available in R to overcome such challenges.
IntroductionThe tidyverse is a collection of R packages that share a common underlying philosophy and are designed to work together. They share common data representations and API design.</description>
    </item>
    
    <item>
      <title>Working with strings in R using stringr</title>
      <link>/post/working-with-strings-in-r-using-stringr/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/working-with-strings-in-r-using-stringr/</guid>
      <description>IntroductionThis is the eleventh post in the series Data Wrangling with R. In the previous post, we learnt to manipulate date and time using the lubridate package. In this post, we will learn to work with string data in R using stringr. Let us begin by installing and loading stringr and a set of other pacakges we will be using.
printcatpastepaste0()sprintf()As we did in the earlier posts in this series, we will use a case study to explore the various features of the stringr package.</description>
    </item>
    
    <item>
      <title>How to work with dates in R</title>
      <link>/post/how-to-work-with-dates-in-r/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-work-with-dates-in-r/</guid>
      <description>IntroductionThis is the tenth post in the series Data Wrangling with R. In the previous post, we learnt to manipulate dataframes using the dplyr package. In this post, we will learn to work with date/time data in R using lubridate, an R package that makes it easy to work with dates and time. Let us begin by installing and loading the lubridate pacakge.
Quick OverviewUse origin to get the origin for the Date and other date/time objects in R.</description>
    </item>
    
    <item>
      <title>Data Manipulation in R with dplyr - Part 1</title>
      <link>/post/data-manipulation-in-r-with-dplyr-part-1/</link>
      <pubDate>Sat, 18 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/data-manipulation-in-r-with-dplyr-part-1/</guid>
      <description>IntroductionThis is the seventh post in the series Data Wrangling with R. In the previous [post], we learnt about using pipes to make our code readable. In this post, we will learn about dplyr.
According to a survey by CrowdFlower, data scientists spend most of their time cleaning and manipulating data rather than mining or modeling them for insights. As such, it becomes important to have tools that make data manipulation faster and easier.</description>
    </item>
    
    <item>
      <title>Readable Code with Pipes</title>
      <link>/post/readable-code-with-pipes/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/readable-code-with-pipes/</guid>
      <description>IntroductionThis is the sixth post in the series Data Wrangling with R. In the previous post, we learnt to export data/code from R. In this post, we will learn about pipes.
When you are dealing with a sequence of multiple operations, R code can get a bit cramped and not so easy on the eyes. The magrittr package by Stefan Milton Bache provides pipes enabling us to write R code that is readable.</description>
    </item>
    
    <item>
      <title>Quick Guide: R &amp; SQLite</title>
      <link>/post/quick-guide-r-sqlite/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/quick-guide-r-sqlite/</guid>
      <description>Connectioncon &amp;lt;- DBI::dbConnect(RSQLite::SQLite(), &amp;quot;:memory:&amp;quot;)Connection Summarysummary(con)## Length Class Mode ## 1 SQLiteConnection S4List TablesdbListTables(con)## [1] &amp;quot;ecom&amp;quot; &amp;quot;sqlite_stat1&amp;quot; &amp;quot;sqlite_stat4&amp;quot;List FieldsDBI::dbListFields(con, &amp;quot;ecom&amp;quot;)## [1] &amp;quot;referrer&amp;quot; &amp;quot;device&amp;quot; &amp;quot;bouncers&amp;quot; &amp;quot;n_visit&amp;quot; &amp;quot;n_pages&amp;quot; &amp;quot;duration&amp;quot;Querying DatadbReadTable(): read entire tabledbGetQuery(): read few rowsdbSendQuery() &amp;amp; dbFetch(): read data in batchesEntire TableDBI::dbReadTable(con, &amp;#39;ecom&amp;#39;)## referrer device bouncers n_visit n_pages duration## 1 google laptop true 10 1 693## 2 yahoo tablet true 9 1 459## 3 direct laptop true 0 1 996## 4 bing tablet false 3 18 468## 5 yahoo mobile true 9 1 955## 6 yahoo laptop false 5 5 135## 7 yahoo mobile true 10 1 75## 8 direct mobile true 10 1 908## 9 bing mobile false 3 19 209## 10 google mobile true 6 1 208## 11 direct laptop true 9 1 738## 12 direct tablet false 6 12 132## 13 direct mobile false 9 14 406## 14 yahoo tablet false 5 8 80## 15 yahoo mobile false 7 1 19## 16 bing laptop true 1 1 995## 17 bing tablet false 5 16 368## 18 google tablet true 7 1 406## 19 social tablet false 7 10 290## 20 social tablet false 2 1 28Few RowsDBI::dbGetQuery(con, &amp;quot;select * from ecom limit 10&amp;quot;)## referrer device bouncers n_visit n_pages duration## 1 google laptop true 10 1 693## 2 yahoo tablet true 9 1 459## 3 direct laptop true 0 1 996## 4 bing tablet false 3 18 468## 5 yahoo mobile true 9 1 955## 6 yahoo laptop false 5 5 135## 7 yahoo mobile true 10 1 75## 8 direct mobile true 10 1 908## 9 bing mobile false 3 19 209## 10 google mobile true 6 1 208Read Data in Batchesquery &amp;lt;- DBI::dbSendQuery(con, &amp;#39;select * from ecom&amp;#39;)result &amp;lt;- DBI::dbFetch(query, n = 15)result## referrer device bouncers n_visit n_pages duration## 1 google laptop true 10 1 693## 2 yahoo tablet true 9 1 459## 3 direct laptop true 0 1 996## 4 bing tablet false 3 18 468## 5 yahoo mobile true 9 1 955## 6 yahoo laptop false 5 5 135## 7 yahoo mobile true 10 1 75## 8 direct mobile true 10 1 908## 9 bing mobile false 3 19 209## 10 google mobile true 6 1 208## 11 direct laptop true 9 1 738## 12 direct tablet false 6 12 132## 13 direct mobile false 9 14 406## 14 yahoo tablet false 5 8 80## 15 yahoo mobile false 7 1 19QueryQuery StatusDBI::dbHasCompleted(query)## [1] FALSEQuery InfoDBI::dbGetInfo(query)## $statement## [1] &amp;quot;select * from ecom&amp;quot;## ## $row.</description>
    </item>
    
    <item>
      <title>RMySQL for Beginners</title>
      <link>/post/rmysql-for-beginners/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/rmysql-for-beginners/</guid>
      <description>ObjectivesInstall and load RMySQL packageConnect to a MySQL database from RDisplay database informationList tables in the databaseCreate new tableImport data into R for analysisExport data from R into MySQLRemove tables and disconnectIntroductionIn real world, data is often stored in relational databases such as MySQL and an analyst is required to extract the data in order to perform any type of analysis.</description>
    </item>
    
    <item>
      <title>A complete guide to importing data into R</title>
      <link>/post/a-complete-guide-to-importing-data-into-r/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/a-complete-guide-to-importing-data-into-r/</guid>
      <description>table {border: 1px solid gray;text-align: left;width: 70%;}th, td {border: 1px solid gray;text-align: left;width: 50%;} 
IntroductionThis is the third post in the series Introduction to tidyverse. In the previous post, we learnt about tibbles. In this post, we will learn to import data into R from different sources. Importing data is the first step in any data analysis workflow.</description>
    </item>
    
  </channel>
</rss>